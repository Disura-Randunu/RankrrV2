{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfTransformer, HashingVectorizer\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "df = pd.read_csv('repeated_letters_words_v9.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-28T00:48:32.028895Z",
     "end_time": "2023-04-28T00:48:32.105530Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Model: Pipeline(steps=[('vect', CountVectorizer(analyzer='char')),\n",
      "                ('tfidf', TfidfTransformer(use_idf=(False, False))),\n",
      "                ('clf', RandomForestClassifier())])\n",
      "Best Parameters: {'clf': RandomForestClassifier(), 'tfidf__use_idf': (False, False), 'vect': CountVectorizer(analyzer='char')}\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         all       1.00      1.00      1.00         9\n",
      "     amazing       1.00      1.00      1.00        22\n",
      "     awesome       1.00      1.00      1.00        16\n",
      "         bad       1.00      1.00      1.00        10\n",
      "   beautiful       1.00      1.00      1.00        19\n",
      "      better       1.00      1.00      1.00        18\n",
      "      boring       1.00      1.00      1.00        14\n",
      "         but       1.00      1.00      1.00         4\n",
      "        cool       1.00      1.00      1.00         8\n",
      "        cute       1.00      1.00      1.00        11\n",
      "   delicious       1.00      1.00      1.00        25\n",
      "   excellent       1.00      1.00      1.00        20\n",
      "        fuck       1.00      1.00      1.00        14\n",
      "         fun       1.00      1.00      1.00         8\n",
      "        good       1.00      1.00      1.00        12\n",
      "       great       1.00      1.00      1.00        14\n",
      "       happy       1.00      1.00      1.00        16\n",
      "    horrible       1.00      1.00      1.00        14\n",
      "         hot       1.00      1.00      1.00        12\n",
      "        huge       1.00      1.00      1.00        12\n",
      "          it       1.00      1.00      1.00         6\n",
      "        just       1.00      1.00      1.00         9\n",
      "        like       1.00      1.00      1.00         7\n",
      "        love       1.00      1.00      1.00         6\n",
      "       nasty       1.00      1.00      1.00        14\n",
      "        need       1.00      1.00      1.00         6\n",
      "        nice       1.00      1.00      1.00        14\n",
      "          no       1.00      1.00      1.00         7\n",
      "     nothing       1.00      1.00      1.00        18\n",
      "        okay       1.00      1.00      1.00        15\n",
      "     perfect       1.00      1.00      1.00        19\n",
      "      pretty       1.00      1.00      1.00        16\n",
      "      really       1.00      1.00      1.00        15\n",
      "        sexy       1.00      1.00      1.00        12\n",
      "        shit       1.00      1.00      1.00         6\n",
      "        slow       1.00      1.00      1.00         5\n",
      "      smooth       1.00      1.00      1.00        15\n",
      "          so       1.00      1.00      1.00         8\n",
      "       super       1.00      1.00      1.00        17\n",
      "       sweet       1.00      1.00      1.00        14\n",
      "       tasty       1.00      1.00      1.00        15\n",
      "         too       1.00      1.00      1.00         4\n",
      "         ugh       1.00      1.00      1.00         8\n",
      "        very       1.00      1.00      1.00        12\n",
      "       waste       1.00      1.00      1.00        20\n",
      "         way       1.00      1.00      1.00         6\n",
      "         woo       0.20      0.17      0.18         6\n",
      "       worse       1.00      1.00      1.00        17\n",
      "         wow       0.50      0.56      0.53         9\n",
      "         yes       1.00      1.00      1.00         7\n",
      "       yummy       1.00      1.00      1.00        11\n",
      "\n",
      "    accuracy                           0.99       622\n",
      "   macro avg       0.97      0.97      0.97       622\n",
      "weighted avg       0.99      0.99      0.99       622\n",
      "\n",
      "Confusion Matrix:\n",
      " [[ 9  0  0 ...  0  0  0]\n",
      " [ 0 22  0 ...  0  0  0]\n",
      " [ 0  0 16 ...  0  0  0]\n",
      " ...\n",
      " [ 0  0  0 ...  5  0  0]\n",
      " [ 0  0  0 ...  0  7  0]\n",
      " [ 0  0  0 ...  0  0 11]]\n",
      "Accuracy Score: 0.9855305466237942\n"
     ]
    }
   ],
   "source": [
    "ngrams = [(2, i) for i in range(2, 15)]\n",
    "\n",
    "df = df.sample(frac = 1)\n",
    "\n",
    "pipeline = Pipeline([\n",
    "    ('vect', CountVectorizer(analyzer='char')),\n",
    "    # ('hashing', HashingVectorizer(analyzer='char')),\n",
    "    ('tfidf', TfidfTransformer()),\n",
    "    ('clf', MultinomialNB())\n",
    "])\n",
    "\n",
    "parameters = {\n",
    "    # 'vect__ngram_range': ngrams,\n",
    "    'vect': [CountVectorizer(analyzer='char')],   # CountVectorizer(analyzer='char_wb')\n",
    "    'tfidf__use_idf': [(True, True), (False, False), (True, False), (False, True)],\n",
    "    'clf': [MultinomialNB(), DecisionTreeClassifier(), RandomForestClassifier(), SVC(), KNeighborsClassifier()],\n",
    "}\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['emphasized'], df['actual'], test_size=0.2, random_state=42)\n",
    "\n",
    "grid_search = GridSearchCV(pipeline, parameters, cv=5, n_jobs=-1)\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "best_model = grid_search.best_estimator_\n",
    "best_params = grid_search.best_params_\n",
    "\n",
    "print(\"Best Model:\", best_model)\n",
    "print(\"Best Parameters:\", best_params)\n",
    "\n",
    "y_pred = best_model.predict(X_test)\n",
    "\n",
    "print(\"Classification Report:\\n\", classification_report(y_test, y_pred))\n",
    "print(\"Confusion Matrix:\\n\", confusion_matrix(y_test, y_pred))\n",
    "print(\"Accuracy Score:\", accuracy_score(y_test, y_pred))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-09T02:46:31.354403Z",
     "end_time": "2023-05-09T02:46:32.584465Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'best_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "\u001B[1;32m~\\AppData\\Local\\Temp\\ipykernel_13036\\1398486980.py\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[1;32m----> 1\u001B[1;33m \u001B[0mbest_model\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mpredict\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;34m\"boooo\"\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m[\u001B[0m\u001B[1;36m0\u001B[0m\u001B[1;33m]\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m",
      "\u001B[1;31mNameError\u001B[0m: name 'best_model' is not defined"
     ]
    }
   ],
   "source": [
    "best_model.predict([\"shttttttttt\"])[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-08T01:43:17.547671Z",
     "end_time": "2023-05-08T01:43:17.574323Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "with open('model_v11.pkl', 'wb') as file:\n",
    "    pickle.dump(best_model, file)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "data": {
      "text/plain": "'perfect'"
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('model_v10.pkl', 'rb') as file:\n",
    "    model = pickle.load(file)\n",
    "\n",
    "repeating_word = 'puuuuuuuuuuurfctttttt'\n",
    "model.predict([repeating_word])[0]"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-05-09T07:18:30.983907Z",
     "end_time": "2023-05-09T07:18:31.021996Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
